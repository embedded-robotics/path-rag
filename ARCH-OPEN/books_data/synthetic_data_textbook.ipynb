{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import backoff\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"data/mn27889/path-rag\")\n",
    "file_path = os.path.join(\"arch\", \"books_set\", \"captions.json\")\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    captions_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_PATH = os.path.join(os.getcwd(), 'api.key')\n",
    "\n",
    "with open(OPENAI_API_PATH) as f:\n",
    "    openai.api_key = f.read().strip()\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.OpenAIError)\n",
    "def completions_with_backoff(**kwargs):\n",
    "    return openai.chat.completions.create(**kwargs)\n",
    "\n",
    "def gpt(user_prompt, system_prompt=\"You are an expert pathologist\", model=\"gpt-4\", temperature=0.7, max_tokens=1000) -> list:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    res = completions_with_backoff(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "    \n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = '''You are provided with a text description (figure caption) of a pathology image. Unfortunately, you don't have access to the original image.\n",
    "Your job is to generate a total of 5 open-ended question/answer pairs from this figure caption starting with \"What\" or \"Where\". Below are the requirements to generate the question/answer pairs:\n",
    "\n",
    "- Avoid quoting or referring to specific facts, terms, abbreviations, dates, numbers or names, as these may reveal the conversation is based on the text information, rather than image itself.\n",
    "- Focus on the visual aspects of the image that can be inferred without the text information\n",
    "- Do not use phrases like \"mentioned\", \"caption\", \"context\", \"without the image\" in the question/answer pairs. Instead, refer to the information as being \"in the image\" or preferably don't mention anything\n",
    "- Ensure that question/anwer pairs are diverse and cover a range of visual aspects of the image\n",
    "- Answer responsibly, avoiding overconfidence, and do not provide medical advice or diagnostic information\n",
    "\n",
    "Caption: {caption}\n",
    "Question:\n",
    "Answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and saving it\n",
    "index_list = []\n",
    "figure_id_list = []\n",
    "letter_list = []\n",
    "caption_list = []\n",
    "uuid_list = []\n",
    "llm_response_list = []\n",
    "\n",
    "start_index = 0\n",
    "current_index = start_index\n",
    "total_records = len(captions_data)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        for index in range(start_index, total_records):\n",
    "            current_index = index\n",
    "            figure_id = captions_data[str(current_index)]['figure_id']\n",
    "            letter = captions_data[str(current_index)]['letter']\n",
    "            caption = captions_data[str(current_index)]['caption']\n",
    "            uuid = captions_data[str(current_index)]['uuid']\n",
    "            \n",
    "            user_prompt = base_prompt.format(caption = caption)\n",
    "            response = gpt(user_prompt)\n",
    "            \n",
    "            index_list.append(current_index)\n",
    "            figure_id_list.append(figure_id)\n",
    "            letter_list.append(letter)\n",
    "            caption_list.append(caption)\n",
    "            uuid_list.append(uuid)\n",
    "            llm_response_list.append(response)\n",
    "\n",
    "            print(\"Index:\", current_index)\n",
    "            print(\"Figure_ID:\", figure_id)\n",
    "            print(\"Letter:\", letter)\n",
    "            print(\"Caption:\", caption)\n",
    "            print(\"UUID:\", uuid)\n",
    "            print()\n",
    "            print(response)\n",
    "            print()\n",
    "    \n",
    "    except Exception as err:\n",
    "        print(\"Something went wrong: \", err)\n",
    "        start_index = current_index\n",
    "        print(\"Waiting for 10 seconds before continuing again with index:\", start_index)\n",
    "        time.sleep(10)\n",
    "\n",
    "    # Break the loop if current_index has completed\n",
    "    if current_index == (total_records - 1):\n",
    "        break\n",
    "\n",
    "llm_qa_pairs_books = pd.DataFrame({'index': index_list, 'figure_id': figure_id_list, 'letter': letter_list,\n",
    "                                   'caption': caption_list, 'uuid': uuid_list, 'llm_qa_pairs_books': llm_response_list})\n",
    "\n",
    "file_name = 'llm_qa_pairs_books_' + str(start_index) + '_' + str(total_records) + '.pkl'\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(llm_qa_pairs_books, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
